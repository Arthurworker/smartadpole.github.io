---
layout: article
title:  "「DL」 生成模型简介"
date:   2019-04-09 15:48:40 +0800
key: generating-model-foundation-20190409
aside:
  toc: true
category: [DL, GAN]
sidebar:
  nav: GAN
---

>

<!--more-->

**2.4.1 自回归模型：pixelRNN 与 pixelCNN**  
自回归模型通过对图像数据的概率分布 $p_{data}(x)$ 进行显式建模，从而定义一个易处理的密度函数，然后利用极大似然估计优化模型：  
\begin{equation}
p_{data}(x)=\prod_{i=1}^n p(x_i\|x_1,x_2,...,x_{i-1})
\end{equation}  
给定 $x_1,x_2,...,x_{i-1}$ 条件下，所有 $p(x_i)$ 的概率乘起来就是图像数据的分布。如果使用 RNN 对上述依然关系建模，就是 pixelRNN；如果使用 CNN，则是 pixelCNN；由于两者都是逐像素操作，所以**速度很慢**；语音领域大火的 WaveNet 就是一个典型的自回归模型；  

**2.4.2 VAE**（变分自编码器）  
定义一个不易处理的密度函数，通过附加的隐变量 z 对密度函数进行建模：真实样本 X 通过神经网络计算出均值方差（假设隐变量服从正态分布），然后通过采样得到采样变量 Z 并进行重构；VAE 和 GAN 均是学习了隐变量 z 到真实数据分布的映射，但是和GAN不同的是：  
- GAN 的思路比较粗暴，使用一个判别器去度量分布转换模块（即生成器）生成的分布与真实数据分布的距离；   
- VAE 则没有那么直观，VAE 通过约束隐变量 z 服从标准正态分布以及重构数据实现了分布转换映射 X=G(z)；   

**2.4.3 生成式模型对比**  
- 自回归模型通过对概率分布显式建模来生成数据；   
- VAE 和 GAN 均是：假设隐变量 z 服从某种分布，并学习一个映射 X=G(z) ，实现隐变量分布 z 与真实数据分布 p_{data}(x) 的转换；   
- GAN 使用判别器去度量映射 X=G(z) 的优劣，而 VAE 通过隐变量 z 与标准正态分布的 KL 散度和重构误差去度量；   

-------------------  
 End
{:.warning}  


# 附录
## A 参考资料
