---
layout: article
title:  "「DL」 生成模型简介"
date:   2019-04-09 15:48:40 +0800
key: generating-model-foundation-20190409
aside:
  toc: true
category: [DL, GAN]
sidebar:
  nav: GAN
---

>生成模型即能够产生同类型新数据的模型；可以根据输入产生我们所期望的输出；  

<!--more-->
生成模型分两类：  
- 可表示出分布函数的；   
- 可生成数据，无法表示出分布函数的；   
典型的应用有超分辨率、图文互转、艺术创作等；   

## 1 自回归模型   
自回归模型通过对图像数据的概率分布 $p_{data}(x)$ 进行显式建模，从而定义一个易处理的密度函数，然后利用最大似然估计优化模型：  
\begin{equation}
p_{data}(x)=\prod_{i=1}^n p(x_i\|x_1,x_2,...,x_{i-1})
\end{equation}  
给定 $x_1,x_2,...,x_{i-1}$ 条件下，所有 $p(x_i)$ 的概率乘起来就是图像数据的分布；如果使用 RNN 对上述依然关系建模，就是 pixelRNN；如果使用 CNN，则是 pixelCNN；由于两者都是逐像素操作，所以**速度很慢**；语音领域大火的 WaveNet 就是一个典型的自回归模型；  

## 2 自编码
自编码网络最初是为了做数据压缩；因为要做训练，所以包含编码器和解码器两部分；后来编码器被单独拿出来作为生成器；  
缺点是模型受训练数据限制太重，泛化能力并不好；于是有了变分自编码；       

## 3 变分自编码器
VAE，编码器不再直接生成编码，而是生成均值和方差，根据他们得到最终的编码，目的是让生成结果服从高斯分布；   
定义一个不易处理的密度函数，通过附加的隐变量 z 对密度函数进行建模：真实样本 X 通过神经网络计算出均值方差（假设隐变量服从正态分布），然后通过采样得到采样变量 Z 并进行重构（生成）；损失函数包括两部分，重建损失和分布相似度度量，前者用的均方差，后者用的 KL 散度；   
VAE 和 GAN 均是学习了隐变量 z 到真实数据分布的映射，但是和 GAN 不同的是：  
- GAN 的思路比较粗暴，使用一个判别器去度量分布转换模块（即生成器）生成的分布与真实数据分布的距离；   
- VAE 则没有那么直观，VAE 通过约束隐变量 z 服从标准正态分布以及重构数据实现了分布转换映射；因不能更好地逼近真实地数据分布，导致生成的图像比较模糊；   

## 4 生成式模型对比  
- 自回归模型通过对概率分布显式建模来生成数据；   
- VAE 和 GAN 均是：假设隐变量 $z$ 服从某种分布，并学习一个映射 $X=G(z)$ ，实现隐变量分布 $z$ 与真实数据分布 $p_{data}(x)$ 的转换；   
- GAN 使用判别器去度量映射 $X=G(z)$ 的优劣，而 VAE 通过隐变量 $z$ 与标准正态分布的 KL 散度和重构误差去度量；   

-------------------  
 End
{:.warning}  


# 附录
## A 参考资料
