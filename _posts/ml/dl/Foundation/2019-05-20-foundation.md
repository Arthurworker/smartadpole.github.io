---
layout: article
title:  "「DL」 深度学习基础知识资源汇总"
date:   2019-05-20 18:08:40 +0800
key: dl-foundation-20190520
aside:
  toc: true
category: [DL, foundation]
tags: 资源
---
<span id='head'></span>  

<!--more-->

# 1 论文
## 1.1 综述

## 1.2 训练
1. [Sequential training algorithm for neural networks](https://arxiv.org/abs/1905.07490)   
*2019-05-17* [paper](https://arxiv.org/abs/1905.07490)    
$\bullet \bullet$   
网络逐层单独训练，最终融合在一起；虽然效果不如整体训练好，但是对于算力有限情况下的大型网络训练很有帮助；   

1. [Overfitting in Synthesis: Theory and Practice](http://cn.arxiv.org/abs/1905.07457)   
*2019-05-17* [paper](https://arxiv.org/abs/1905.07457)   
$\bullet \bullet$    

## 1.3 归一化
1. [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)   
*2017-06-08* [Paper](https://arxiv.org/abs/1706.02515) | [tensorflow](https://github.com/bioinf-jku/SNNs) | [zhihu](https://www.zhihu.com/question/60910412) | [reddit](https://www.reddit.com/r/MachineLearning/comments/6g5tg1/r_selfnormalizing_neural_networks_improved_elu/dio0qac/)      


1. [ROI Regularization for Semi-supervised and Supervised Learning](http://cn.arxiv.org/abs/1905.08615)   
*2019-05-15* [paper](https://arxiv.org/abs/1905.08615)  

## 1.4 激活函数
1. [Neurons Activation Visualization and Information Theoretic Analysis](http://cn.arxiv.org/abs/1905.08618)   
*2019-05-14* [paper](https://arxiv.org/abs/1905.08618)   


-------------------  
[End](#head)
{:.warning}  
