---
layout: article
title:  "「DL」 深度学习中的归一化"
date:   2019-04-28 11:08:40 +0800
key: DL-normal-20190428
aside:
  toc: true
category: [DL, foundation]
---
>[Batch Normalization](https://arxiv.org/abs/1502.03167)，[Layer Normalizaiton](https://arxiv.org/abs/1607.06450)，[Instance Normalization](https://arxiv.org/abs/1607.08022)，[Group Normalization](
https://arxiv.org/abs/1803.08494)，[Switchable Normalization](https://arxiv.org/abs/1806.10779)    

<!--more-->

归一化，正则化，标准化；    

1. 什么是归一化   
1. 为什么要做归一化   
1. 归一化的方式有哪些   
1. 各自的优势    
1. 原理解析   

1. [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)   
*2017-06-08* [Paper](https://arxiv.org/abs/1706.02515) | [tensorflow](https://github.com/bioinf-jku/SNNs) | [zhihu](https://www.zhihu.com/question/60910412) | [reddit](https://www.reddit.com/r/MachineLearning/comments/6g5tg1/r_selfnormalizing_neural_networks_improved_elu/dio0qac/)      

-------------------  
End
{:.warning}  
