---
layout: article
title:  "「DL」 深度学习常见问题"
date:   2019-03-18 17:00:40 +0800
key: dl-issue-20190318
aside:
  toc: true
tags: Q&A
category: [DL]
---

:o: <span id="1">**1. 为什么图像分类的输入大多是 $224 \times 224$**</span>    
<!--more-->   
用于分类的卷积网络包括下采样和分类；   
- **一个分类对应的最后一个特征图的大小——$7 \times 7$**   
最后一个特征图经过分类操作（全连接或全局池化）得到分类结果，一个分类对应的最后一层特征图大小可以是 $3 \times 3$，$5 \times 5$，$7 \times 7$ 等；其中 $7 \times 7$ 更合理，因为尺寸过小会造成信息丢失严重，尺寸太大，信息的抽象程度不够，计算量也大；$7 \times 7$ 较为平衡；    
- **整个卷积网络下采样的程度为—— $2^5$**  
图像从输入到最后一层，分辨率降低的程度通常是 $2^n$；  
下采样 $1/4$，输入是 $7 \times 2^4=112$；下采样 $1/5$，输入是 $7 \times 2^5=224$；下采样 $1 / 6$，输入是 $7 \times  2^6=228$；  
而 imagenet 的图像大小都在 300 左右；与 300 最接近的就是 224 了，故选择了 $2^5$；

>以上只是多多种巧合情况的综合，使得经典论文中大多使用 $224 \times 224$ 的输入尺寸；实际应用中，仍需根据网络本身结构（下采样程度）和采集到的图像尺寸来综合考虑最终使用输入尺寸；   

[1]. 龙鹏. 【AI-1000问】为什么深度学习图像分类的输入多是224*224[EB/OL]. <https://zhuanlan.zhihu.com/p/58188430>. 2019-03-03/2019-03-18.    

:o: <span id="2">**2. 计算 feature map 大小**</span>    
输出的 feature map 大小：
$\mathbf{H_{out} = { {H_{in} + 2 \times {pad} - kernel} \over stride} + 1}$   
$\mathbf{W_{out} = { {W_{in} + 2 \times {pad} - kernel} \over stride} + 1}$   

*注：当 stride 为 1 时，若 $\mathbf{pad = { {kernel − 1} \over 2} }$，则输出 feature map大小不变*   


-------------------  
 End8
{:.warning}  



## 附录
### A  参考资料
