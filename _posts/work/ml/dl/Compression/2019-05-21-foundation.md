---
layout: article
title:  "「DL」 模型压缩资源汇总"
date:   2019-05-21 09:08:40 +0800
key: deep-compression-foundation-20190521
aside:
  toc: true
category: [DL, compression]
tags: 资源
---
<span id='head'></span>  


<!--more-->


# 1 综述

# 2 理论
1. [Doctor of Crosswise: Reducing Over-parametrization in Neural Networks](http://cn.arxiv.org/abs/1905.10324)   
*2019-05-24* [paper](https://arxiv.org/abs/1905.10324)   

# 3 剪枝
1. [
FeTa: A DCA Pruning Algorithm with Generalization Error Guarantees](https://arxiv.org/abs/1803.04239)   
*2018-03-12* [paper](https://arxiv.org/abs/1803.04239)   

1. [Revisiting hard thresholding for DNN pruning](http://cn.arxiv.org/abs/1905.08793)   
*2019-05-21* [paper](https://arxiv.org/abs/1905.08793)   

# 5 低秩分解
1. [Learning Low-Rank Approximation for CNNs](http://cn.arxiv.org/abs/1905.10145)   
*2019-05-24* [paper](https://arxiv.org/abs/1905.10145)   

# 6 权值量化
1. [Integer Discrete Flows and Lossless Compression](http://cn.arxiv.org/abs/1905.07376)   
*2019-05-17* [paper](https://arxiv.org/abs/1905.07376)   

# 7 其他
1. [Dream Distillation: A Data-Independent Model Compression Framework](http://cn.arxiv.org/abs/1905.07072)   
ICML 2019 workshop *2019-05-17* [paper](https://arxiv.org/abs/1905.07072)   
$\bullet \bullet$   
无需重新训练的模型压缩方法；   

1. [DARC: Differentiable ARchitecture Compression](http://cn.arxiv.org/abs/1905.08170)   
*2019-05-20* [paper](https://arxiv.org/abs/1905.08170)   

1. [Geometry of Deep Convolutional Networks](http://cn.arxiv.org/abs/1905.08922)   
*2019-05-21* [paper](https://arxiv.org/abs/1905.08922)   


-------------------  
[End](#head)
{:.warning}  
